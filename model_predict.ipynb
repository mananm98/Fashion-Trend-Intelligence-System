{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0809 17:20:25.157788 140735510987648 deprecation.py:323] From /Users/mananmehta/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import efficientnet.keras as efn \n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 17:20:27.352929 140735510987648 deprecation.py:323] From <ipython-input-2-61b31bc823f7>:6: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "# Object Detection to detect T-shirts and crop them from images\n",
    "saved_model_dir = './fashionpedia-api/model'  # specify the model dir here\n",
    "\n",
    "\n",
    "session = tf.Session(graph=tf.Graph())\n",
    "_ = tf.saved_model.loader.load(session, ['serve'], saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 17:20:42.774966 140735510987648 deprecation.py:506] From /Users/mananmehta/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "/Users/mananmehta/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Loading trained siamese triplet Model\n",
    "model = load_model('/Users/mananmehta/Downloads/model2_epoch_2_max_pooling_with_shallow_layers_lr_0.3.h5')\n",
    "model._make_predict_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_t_shirt_site(path):\n",
    "    '''\n",
    "    Checks whether an image contains T-Shirt or not\n",
    "    '''\n",
    "    with open(path,'rb') as f:\n",
    "        np_image_string = np.array([f.read()])\n",
    "    \n",
    "    num_detections, detection_classes, detection_scores, image_info = session.run(['NumDetections:0','DetectionClasses:0', 'DetectionScores:0','ImageInfo:0']\n",
    "                                                                                      ,feed_dict = {'Placeholder:0':np_image_string})\n",
    "    num_detections = np.squeeze(num_detections.astype(np.int32), axis=(0,))\n",
    "    detection_scores = np.squeeze(detection_scores, axis=(0,))[0:num_detections]\n",
    "    detection_classes = np.squeeze(detection_classes.astype(np.int32), axis=(0,))[0:num_detections] \n",
    "    \n",
    "    for i in range(num_detections):\n",
    "        if detection_classes[i] == 2 and detection_scores[i] > 0.90 : \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns embedding matrix for a folder of images\n",
    "def generate_embedding_matrix_sites(path):\n",
    "    '''\n",
    "    Generates embedding matrix for site images, of type (img_path,embedding)\n",
    "    '''\n",
    "    embeddings = []\n",
    "    for file in os.listdir(path):\n",
    "        if check_t_shirt_site(path + '/' + file):\n",
    "            \n",
    "            img = image.load_img(path + '/' + file,target_size = (300,225))\n",
    "            img = image.img_to_array(img)\n",
    "            img = img/255\n",
    "            img = np.expand_dims(img,axis = 0)\n",
    "            embedding = model.predict(img)\n",
    "            embedding = np.squeeze(embedding)\n",
    "            embeddings.append([path + '/' + file,embedding])\n",
    "    return np.array(embeddings)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = json.load(open('./fashionpedia-api/data/demo/category_attributes_descriptions.json'))\n",
    "def check_t_shirt(path):\n",
    "        '''\n",
    "        Checks whether a Trendy image contains T-Shirt or not.\n",
    "        If yes it returns cropped portion of image, containing T-shirt\n",
    "        '''\n",
    "    with open(path,'rb') as f:\n",
    "        np_image_string = np.array([f.read()])\n",
    "    \n",
    "    num_detections, detection_boxes, detection_classes, detection_scores, image_info = session.run(['NumDetections:0','DetectionBoxes:0','DetectionClasses:0', 'DetectionScores:0','ImageInfo:0']\n",
    "                                                                                      ,feed_dict = {'Placeholder:0':np_image_string})\n",
    "    num_detections = np.squeeze(num_detections.astype(np.int32), axis=(0,))\n",
    "    detection_boxes = np.squeeze(detection_boxes * image_info[0, 2], axis=(0,))[0:num_detections]\n",
    "    detection_scores = np.squeeze(detection_scores, axis=(0,))[0:num_detections]\n",
    "    detection_classes = np.squeeze(detection_classes.astype(np.int32), axis=(0,))[0:num_detections]\n",
    "    \n",
    "    for i in range(num_detections):\n",
    "        if detection_classes[i] == 2 and detection_scores[i] > 0.90 : \n",
    "            top,left,bottom,right = detection_boxes[i]\n",
    "            bbox = (left,top,right,bottom)\n",
    "            return (True,bbox)\n",
    "    return (False,(0,0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_matrix_trendy(path):\n",
    "    '''\n",
    "    Generates Embedding matrix of trendy images\n",
    "    '''\n",
    "    embeddings = []\n",
    "    for file in os.listdir(path):\n",
    "        is_t_shirt, bbox = check_t_shirt(path + '/' + file)\n",
    "        \n",
    "        if is_t_shirt == False:\n",
    "            continue\n",
    "\n",
    "        img = image.load_img(path + '/' + file)\n",
    "        img = img.crop(bbox)\n",
    "        img = img.resize((225,300))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        img = np.expand_dims(img,axis = 0)\n",
    "        embedding = model.predict(img)\n",
    "        embedding = np.squeeze(embedding)\n",
    "        embeddings.append([path + '/' + file,embedding])\n",
    "        \n",
    "    return np.array(embeddings)       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a,b):\n",
    "    # Calculates distance between two embeddings\n",
    "        return np.sqrt(np.sum((a-b)**2))\n",
    "    \n",
    "def find_top_neighbours(trendy_embedding_matrix,site_embedding_matrix):\n",
    "    '''\n",
    "    Finds top 5 nearest neighbours for each trendy image\n",
    "    '''\n",
    "    top_hits = []\n",
    "    for trendy_emb in trendy_embedding_matrix:\n",
    "        distances = []\n",
    "        for site_emb in site_embedding_matrix:\n",
    "            distances.append((site_emb[0],distance(trendy_emb[1],site_emb[1])))\n",
    "            \n",
    "        distances = sorted(distances,key = lambda x : x[1])[:5]\n",
    "        top_hits.append([trendy_emb[0],distances])\n",
    "\n",
    "    return top_hits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mananmehta/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#trend = generate_embedding_matrix_trendy('/Users/mananmehta/Desktop/dataset')\n",
    "#sites = generate_embedding_matrix_sites('/Users/mananmehta/Desktop/dataset 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hello = find_top_neighbours(trend,sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axes = []\n",
    "#fig = plt.figure(figsize = (20,20))\n",
    "#c = 0\n",
    "#for i in range(len(hello)):\n",
    "#    img = image.load_img(hello[i][0],target_size = (300,225))\n",
    "#    axes.append(fig.add_subplot(14,6,i+c+1))\n",
    "#    plt.imshow(img)\n",
    "#    for j in range(len(hello[i][1])):\n",
    "#        axes.append(fig.add_subplot(14,6,i+j+2+c))\n",
    "#        img = image.load_img(hello[i][1][j][0],target_size = (300,225))\n",
    "#        plt.imshow(img)\n",
    "#    c += 5\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
